import matplotlib.pyplot as plt
import numpy as np
import torch
# 假设 attention_weights 是你的注意力权重矩阵，形状为 (seq_len, seq_len)
# 为了示例，我们这里使用一个随机矩阵
seq_len = 10
attention_weights_list = [torch.tensor([[[[0.5070]],

         [[0.5263]],

         [[0.4699]],

         ...,

         [[0.4919]],

         [[0.5066]],

         [[0.5128]]],


        [[[0.5026]],

         [[0.5208]],

         [[0.4660]],

         ...,

         [[0.4959]],

         [[0.5068]],

         [[0.5108]]],


        [[[0.5061]],

         [[0.5290]],

         [[0.4614]],

         ...,

         [[0.4923]],

         [[0.5081]],

         [[0.5145]]],


        ...,


        [[[0.5028]],

         [[0.5223]],

         [[0.4637]],

         ...,

         [[0.4957]],

         [[0.5072]],

         [[0.5116]]],


        [[[0.5026]],

         [[0.5209]],

         [[0.4659]],

         ...,

         [[0.4959]],

         [[0.5068]],

         [[0.5109]]],


        [[[0.5057]],

         [[0.5296]],

         [[0.4588]],

         ...,

         [[0.4926]],

         [[0.5086]],

         [[0.5149]]]]), torch.tensor([[[[0.4828]],

         [[0.4818]],

         [[0.5312]],

         ...,

         [[0.5275]],

         [[0.5235]],

         [[0.4791]]],


        [[[0.4846]],

         [[0.4827]],

         [[0.5303]],

         ...,

         [[0.5223]],

         [[0.5243]],

         [[0.4802]]],


        [[[0.4832]],

         [[0.4816]],

         [[0.5296]],

         ...,

         [[0.5208]],

         [[0.5239]],

         [[0.4830]]],


        ...,


        [[[0.4839]],

         [[0.4820]],

         [[0.5304]],

         ...,

         [[0.5222]],

         [[0.5241]],

         [[0.4812]]],


        [[[0.4865]],

         [[0.4814]],

         [[0.5280]],

         ...,

         [[0.5220]],

         [[0.5215]],

         [[0.4820]]],


        [[[0.4833]],

         [[0.4795]],

         [[0.5288]],

         ...,

         [[0.5209]],

         [[0.5222]],

         [[0.4851]]]]), torch.tensor([[[[0.5049]],

         [[0.4946]],

         [[0.4950]],

         ...,

         [[0.5054]],

         [[0.4953]],

         [[0.4949]]],


        [[[0.5049]],

         [[0.4967]],

         [[0.4970]],

         ...,

         [[0.5021]],

         [[0.4953]],

         [[0.4965]]],


        [[[0.5045]],

         [[0.4964]],

         [[0.4952]],

         ...,

         [[0.5036]],

         [[0.4938]],

         [[0.4957]]],


        ...,


        [[[0.5046]],

         [[0.4974]],

         [[0.4962]],

         ...,

         [[0.5048]],

         [[0.4939]],

         [[0.4974]]],


        [[[0.5054]],

         [[0.4970]],

         [[0.4963]],

         ...,

         [[0.5046]],

         [[0.4940]],

         [[0.4972]]],


        [[[0.5048]],

         [[0.4982]],

         [[0.4941]],

         ...,

         [[0.5062]],

         [[0.4924]],

         [[0.4960]]]]), torch.tensor([[[[0.5230]],

         [[0.5709]],

         [[0.4567]],

         ...,

         [[0.4739]],

         [[0.4737]],

         [[0.4781]]],


        [[[0.5163]],

         [[0.5597]],

         [[0.4337]],

         ...,

         [[0.4782]],

         [[0.4609]],

         [[0.5281]]],


        [[[0.5022]],

         [[0.5519]],

         [[0.4741]],

         ...,

         [[0.4021]],

         [[0.5017]],

         [[0.4285]]],


        ...,


        [[[0.5070]],

         [[0.5587]],

         [[0.4571]],

         ...,

         [[0.4634]],

         [[0.4833]],

         [[0.4935]]],


        [[[0.4746]],

         [[0.5558]],

         [[0.4394]],

         ...,

         [[0.4418]],

         [[0.4902]],

         [[0.4889]]],


        [[[0.5012]],

         [[0.5783]],

         [[0.4201]],

         ...,

         [[0.4417]],

         [[0.4807]],

         [[0.4926]]]])]
# 绘制热力图
plt.figure(figsize=(8, 6))
plt.imshow(attention_weights_list, cmap='viridis', interpolation='nearest')
plt.colorbar()  # 显示颜色条

plt.xlabel('Key Positions')
plt.ylabel('Query Positions')
plt.title('Attention Heatmap')

# 显示图表
plt.show()
